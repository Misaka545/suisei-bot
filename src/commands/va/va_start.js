// src/commands/va/va_start.js
const { ChannelType } = require("discord.js");
const { AudioPlayerStatus, EndBehaviorType } = require("@discordjs/voice");

// Helpers/States/Services b·∫°n ƒë√£ t√°ch s·∫µn
const { ensureVA } = require("../../utils/vaState");
const { ensureChat, aiGenerate } = require("../../utils/aiChatState");
const { ensureMusic, connectIfNeeded } = require("../../utils/musicState");
const { geminiTranscribe } = require("../../services/geminiService");
const { ttsResourceFromText } = require("../../services/ttsService");

// Audio utils (ffmpegPath, prism, ‚Ä¶). C√≥ th·ªÉ b·∫°n g·ªôp ch√∫ng trong 1 util.
const { ffmpegPath, prism } = require("../../utils/audioProcessing");

// M·ªôt s·ªë tu·ª≥ ch·ªçn nh·∫π cho pipeline
const EPHEMERAL_FLAG = 1 << 6;
const WARMUP_FRAMES = 3;      // b·ªè v√†i frame ƒë·∫ßu ƒë·ªÉ tr√°nh h∆∞ ƒë·∫ßu g√≥i
const HARD_TIMEOUT_MS = 7000; // c·ª©ng timeout thu √¢m 1 l∆∞·ª£t n√≥i

module.exports = async function handleVaStart(interaction) {
  const guild = interaction.guild;
  const member = await guild.members.fetch(interaction.user.id).catch(() => null);
  const voiceChannel = member?.voice?.channel;

  if (!voiceChannel) {
    return interaction.reply({ content: "‚ùå Join a voice channel first.", flags: EPHEMERAL_FLAG });
  }

  // Stage channel guard: ph·∫£i l√† Speaker (kh√¥ng ph·∫£i Audience)
  if (voiceChannel.type === ChannelType.GuildStageVoice && member.voice.suppress) {
    return interaction.reply({
      content: "üéôÔ∏è B·∫°n ƒëang l√† **Audience** trong Stage. H√£y **Request to Speak** r·ªìi ch·∫°y l·∫°i `/va start`.",
      flags: EPHEMERAL_FLAG,
    });
  }

  // B·∫≠t VA
  const va = ensureVA(guild.id);
  va.active = true;
  va.processing = false;

  await interaction.reply("üéôÔ∏è Voice Assistant: **ON**. (Listening)");

  // K·∫øt n·ªëi voice ‚Äî quan tr·ªçng: selfDeaf=false ƒë·ªÉ nh·∫≠n mic
  const st = await connectIfNeeded(interaction, voiceChannel, { selfDeaf: false });
  ensureMusic(guild.id); // ƒë·∫£m b·∫£o c√≥ state nh·∫°c (ƒë·ªÉ t·∫°m d·ª´ng/unpause khi bot n√≥i)

  const receiver = st.connection.receiver;

  // M·ªói l·∫ßn ai ƒë√≥ b·∫Øt ƒë·∫ßu n√≥i -> thu v√† x·ª≠ l√Ω
  receiver.speaking.on("start", async (userId) => {
    try {
      if (!va.active || va.processing) return;
      const m = guild.members.cache.get(userId);
      if (!m || m.user.bot) return;

      // Ch·ªâ x·ª≠ l√Ω ng∆∞·ªùi ƒëang g·ªçi l·ªánh? (tu·ª≥ ch·ªçn)
      // if (m.id !== interaction.user.id) return;

      va.processing = true;
      console.log(`[VA] speaking start from ${m.user.tag} (${userId})`);

      // 1) Opus stream t·ª´ Discord -> decode PCM 48k mono
      const opus = receiver.subscribe(userId, {
        end: { behavior: EndBehaviorType.AfterSilence, duration: 1200 },
        autoDestroy: true,
      });

      opus.on("error", (e) => console.warn("[VA] opus stream error:", e?.message || e));

      const decoder = new prism.opus.Decoder({
        frameSize: 960, // 20ms @ 48k
        channels: 1,
        rate: 48000,
      });

      decoder.on("error", (e) => {
        // frame h·ªèng ‚Äî b·ªè qua
        console.warn("[VA] opus decoder error:", e?.message || e);
      });

      const pcm = opus.pipe(decoder);

      // B·ªè 1 v√†i khung ƒë·∫ßu (warm-up)
      const { Transform } = require("stream");
      let warmupLeft = WARMUP_FRAMES;
      const warmupStripper = new Transform({
        transform(chunk, _enc, cb) {
          if (warmupLeft > 0) { warmupLeft--; return cb(); }
          cb(null, chunk);
        },
      });

      // 2) PCM 48k mono -> WAV 16k mono b·∫±ng ffmpeg
      const ff = new prism.FFmpeg({
        command: ffmpegPath,
        args: [
          "-f","s16le","-ar","48000","-ac","1","-i","pipe:0",
          "-ar","16000","-ac","1","-f","wav","pipe:1","-loglevel","quiet",
        ],
      });

      ff.on("error", (e) => console.warn("[VA] ffmpeg transcode error:", e?.message || e));

      let pcmBytes = 0, framesSeen = 0;
      pcm.on("data", (c) => { pcmBytes += c.length; framesSeen++; });

      const wavStream = pcm.pipe(warmupStripper).pipe(ff);

      // HARD TIMEOUT ƒë·ªÉ kh√¥ng treo
      const hardTimeout = setTimeout(() => {
        console.warn("[VA] hard timeout reached; forcing stream end");
        try { opus.destroy(); } catch {}
        try { pcm.destroy(); } catch {}
        try { warmupStripper.destroy(); } catch {}
        try { ff.destroy(); } catch {}
      }, HARD_TIMEOUT_MS);

      // Thu WAV buffer
      const wav = await new Promise((resolve, reject) => {
        const chunks = [];
        wavStream.on("data", (c) => chunks.push(c));
        wavStream.on("error", reject);
        wavStream.on("end", () => resolve(Buffer.concat(chunks)));
      }).finally(() => clearTimeout(hardTimeout));

      const wavBytes = wav?.length || 0;
      console.log(`[VA] frames=${framesSeen} | PCM bytes=${pcmBytes} | WAV bytes=${wavBytes}`);

      if (!pcmBytes || wavBytes < 2000) {
        va.processing = false;
        await interaction.followUp({
          content: "‚ö†Ô∏è VA kh√¥ng nh·∫≠n ƒë∆∞·ª£c √¢m thanh. Ki·ªÉm tra quy·ªÅn mic / n√≥i g·∫ßn h∆°n / t·∫Øt server deafen.",
          flags: EPHEMERAL_FLAG,
        }).catch(() => {});
        return;
      }

      // 3) STT (Gemini)
      let transcript = "";
      try {
        transcript = await geminiTranscribe(wav);
        console.log(`[VA] transcript="${(transcript || "").slice(0, 120)}${(transcript || "").length > 120 ? "..." : ""}"`);
      } catch (e) {
        console.error("[VA] STT error:", e);
        va.processing = false;
        await interaction.followUp({ content: "‚ùå L·ªói nh·∫≠n di·ªán gi·ªçng n√≥i (STT).", flags: EPHEMERAL_FLAG }).catch(() => {});
        return;
      }

      if (!transcript) {
        va.processing = false;
        return;
      }

      // 4) Wakeword (n·∫øu c√≥)
      if (va.wakeword && !transcript.toLowerCase().includes(va.wakeword.toLowerCase())) {
        console.log("[VA] wakeword not found, ignore");
        va.processing = false;
        return;
      }
      if (va.wakeword) {
        const re = new RegExp(va.wakeword, "i");
        transcript = transcript.replace(re, "").trim();
      }

      // 5) LLM (Gemini) ‚Äî h·ªôi tho·∫°i theo k√™nh
      const session = ensureChat(interaction.channelId);
      let replyText = "";
      try {
        replyText = await aiGenerate(session, transcript);
        console.log(`[VA] reply="${replyText.slice(0, 120)}${replyText.length > 120 ? "..." : ""}"`);
      } catch (e) {
        console.error("[VA] LLM error:", e);
        va.processing = false;
        await interaction.followUp({ content: "‚ùå L·ªói AI t·∫°o c√¢u tr·∫£ l·ªùi.", flags: EPHEMERAL_FLAG }).catch(() => {});
        return;
      }

      // 6) TTS & ph√°t ‚Äî t·∫°m d·ª´ng nh·∫°c n·∫øu ƒëang ph√°t
      const stNow = ensureMusic(guild.id);
      const pausedForVA =
        stNow?.player && stNow.player.state.status === AudioPlayerStatus.Playing
          ? stNow.player.pause(true)
          : false;

      try {
        const ttsRes = await ttsResourceFromText(replyText, va.lang);
        st.player.play(ttsRes);
      } catch (e) {
        console.error("[VA] TTS error:", e);
        await interaction.followUp({ content: `üó®Ô∏è ${replyText}`, flags: EPHEMERAL_FLAG }).catch(() => {});
        if (pausedForVA) stNow?.player?.unpause();
        va.processing = false;
        return;
      }

      // Khi TTS xong -> unpause nh·∫°c + s·∫µn s√†ng l∆∞·ª£t n√≥i m·ªõi
      const onIdle = () => {
        st.player.off(AudioPlayerStatus.Idle, onIdle);
        if (pausedForVA) stNow?.player?.unpause();
        va.processing = false;
        console.log("[VA] TTS finished");
      };
      st.player.on(AudioPlayerStatus.Idle, onIdle);
    } catch (e) {
      console.error("[VA] pipeline error:", e);
      va.processing = false;
      await interaction.followUp({ content: "‚ö†Ô∏è VA pipeline error.", flags: EPHEMERAL_FLAG }).catch(() => {});
    }
  });
};
